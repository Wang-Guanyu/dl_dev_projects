{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 2: CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n",
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Prepare & label dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_examples_per_class = 10000\n",
    "num_classes = 100\n",
    "\n",
    "classes = ['airplane','alarm clock','ambulance','angel','ant','anvil','apple','axe','banana','bandage','barn','baseball bat','baseball',\n",
    "           'basket','basketball','bathtub','beach','bear','beard','bed','bee','belt','bicycle','binoculars','birthday cake','blueberry',\n",
    "           'book','boomerang','bottlecap','bowtie','bracelet','brain','bread','broom','bulldozer','bus','bus','butterfly','cactus','cake',\n",
    "           'calculator','calendar','camel','camera','campfire','candle','cannon','canoe','car','carrot','cello','computer',\n",
    "           'cat','chandelier','clock','cloud','coffee cup','compass','cookie','couch','cow','crab','crayon','crocodile','crown',\n",
    "           'cup','diamond','dog','dolphin','donut','dragon','dresser','drill','drums','duck','dumbbell','ear','elbow',\n",
    "           'elephant','envelope','eraser','eye','eyeglasses','face','fan','feather','fence','finger','fire hydrant',\n",
    "           'fireplace','firetruck','fish','flamingo','flashlight','flip flops','floor lamp','flower','flying saucer',\n",
    "           'foot','fork']\n",
    "\n",
    "x_data = np.load('./x_data_100_classes_10k.npy')\n",
    "labels = [np.full((num_examples_per_class,), classes.index(qdraw)) for qdraw in classes]\n",
    "y_data = np.concatenate(labels,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Let's take a look at one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_object(obj):\n",
    "    # Reshape 784 array into 28x28 image\n",
    "    image = obj.reshape([28,28])\n",
    "    fig, axes = plt.subplots(1, )\n",
    "    fig.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/ECkKD8QKcoPRIryA5Gi/ECk/g8IGwPPsLS7iwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x290907ac0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label of this data is: 6\n"
     ]
    }
   ],
   "source": [
    "show_object(x_data[66666])\n",
    "print('The label of this data is: %d' % y_data[66666])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Shuffle & preprocessing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffling function\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data,y_data = unison_shuffled_copies(x_data,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600000, 28, 28, 1)\n",
      "(300000, 28, 28, 1)\n",
      "(100000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "imcols = 28\n",
    "imrows = 28\n",
    "image_shape = (imrows, imcols, 1)\n",
    "\n",
    "# Preprocessing dataset\n",
    "x_train, x_rest, y_train, y_rest = train_test_split(x_data,y_data,test_size=0.4)\n",
    "x_validation, x_test, y_validation, y_test = train_test_split(x_rest,y_rest,test_size=0.25)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_validation = x_validation.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train/255.0 # Normalize training data\n",
    "x_validation = x_validation/255.0 # Normalize validation data\n",
    "x_test = x_test/255.0 # Normalize testing data\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], imrows, imcols, 1)\n",
    "x_validation = x_validation.reshape(x_validation.shape[0], imrows, imcols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], imrows, imcols, 1)\n",
    "y_train = keras.utils.to_categorical(y_train,num_classes)\n",
    "y_validation = keras.utils.to_categorical(y_validation,num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test,num_classes)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_validation.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 20)        520       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 50)        25050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2450)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               1225500   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               50100     \n",
      "=================================================================\n",
      "Total params: 1,303,170\n",
      "Trainable params: 1,302,170\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(20,(5,5),input_shape=(image_shape),activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(50,(5,5),activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "# Define loss function & optimizer\n",
    "adam = keras.optimizers.Adam(lr=0.005,beta_1=0.9,beta_2=0.999,epsilon=1e-08,decay=0.01)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=adam,metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600000 samples, validate on 300000 samples\n",
      "Epoch 1/200\n",
      "600000/600000 [==============================] - 18s 29us/step - loss: 2.8984 - acc: 0.3217 - val_loss: 3.9625 - val_acc: 0.0717\n",
      "Epoch 2/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 2.0852 - acc: 0.4934 - val_loss: 3.3838 - val_acc: 0.2804\n",
      "Epoch 3/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.9201 - acc: 0.5336 - val_loss: 2.8891 - val_acc: 0.4737\n",
      "Epoch 4/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.8310 - acc: 0.5545 - val_loss: 2.3797 - val_acc: 0.5970\n",
      "Epoch 5/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.7712 - acc: 0.5698 - val_loss: 1.9646 - val_acc: 0.6473\n",
      "Epoch 6/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.7307 - acc: 0.5798 - val_loss: 1.6535 - val_acc: 0.6749\n",
      "Epoch 7/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.6995 - acc: 0.5884 - val_loss: 1.4342 - val_acc: 0.6917\n",
      "Epoch 8/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.6727 - acc: 0.5945 - val_loss: 1.3299 - val_acc: 0.6976\n",
      "Epoch 9/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.6509 - acc: 0.6002 - val_loss: 1.2558 - val_acc: 0.7043\n",
      "Epoch 10/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.6338 - acc: 0.6041 - val_loss: 1.2146 - val_acc: 0.7076\n",
      "Epoch 11/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.6198 - acc: 0.6089 - val_loss: 1.2005 - val_acc: 0.7073\n",
      "Epoch 12/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.6074 - acc: 0.6114 - val_loss: 1.1828 - val_acc: 0.7106\n",
      "Epoch 13/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.5977 - acc: 0.6137 - val_loss: 1.1704 - val_acc: 0.7124\n",
      "Epoch 14/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.5864 - acc: 0.6159 - val_loss: 1.1662 - val_acc: 0.7127\n",
      "Epoch 15/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.5791 - acc: 0.6181 - val_loss: 1.1573 - val_acc: 0.7151\n",
      "Epoch 16/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.5680 - acc: 0.6205 - val_loss: 1.1510 - val_acc: 0.7165\n",
      "Epoch 17/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.5657 - acc: 0.6213 - val_loss: 1.1432 - val_acc: 0.7175\n",
      "Epoch 18/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.5578 - acc: 0.6227 - val_loss: 1.1453 - val_acc: 0.7169\n",
      "Epoch 19/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.5522 - acc: 0.6250 - val_loss: 1.1332 - val_acc: 0.7198\n",
      "Epoch 20/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.5480 - acc: 0.6259 - val_loss: 1.1327 - val_acc: 0.7200\n",
      "Epoch 21/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.5399 - acc: 0.6275 - val_loss: 1.1274 - val_acc: 0.7211\n",
      "Epoch 22/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.5356 - acc: 0.6287 - val_loss: 1.1311 - val_acc: 0.7205\n",
      "Epoch 23/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.5315 - acc: 0.6299 - val_loss: 1.1295 - val_acc: 0.7210\n",
      "Epoch 24/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.5271 - acc: 0.6313 - val_loss: 1.1168 - val_acc: 0.7236\n",
      "Epoch 25/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.5248 - acc: 0.6312 - val_loss: 1.1164 - val_acc: 0.7237\n",
      "Epoch 26/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.5215 - acc: 0.6319 - val_loss: 1.1125 - val_acc: 0.7245\n",
      "Epoch 27/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.5179 - acc: 0.6324 - val_loss: 1.1111 - val_acc: 0.7246\n",
      "Epoch 28/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.5164 - acc: 0.6340 - val_loss: 1.1087 - val_acc: 0.7258\n",
      "Epoch 29/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.5115 - acc: 0.6344 - val_loss: 1.1077 - val_acc: 0.7261\n",
      "Epoch 30/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.5108 - acc: 0.6349 - val_loss: 1.1038 - val_acc: 0.7260\n",
      "Epoch 31/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.5076 - acc: 0.6357 - val_loss: 1.1055 - val_acc: 0.7253\n",
      "Epoch 32/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.5030 - acc: 0.6365 - val_loss: 1.1015 - val_acc: 0.7270\n",
      "Epoch 33/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.5008 - acc: 0.6371 - val_loss: 1.1025 - val_acc: 0.7264\n",
      "Epoch 34/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.5005 - acc: 0.6375 - val_loss: 1.0990 - val_acc: 0.7273\n",
      "Epoch 35/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4967 - acc: 0.6383 - val_loss: 1.0985 - val_acc: 0.7281\n",
      "Epoch 36/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4942 - acc: 0.6388 - val_loss: 1.0982 - val_acc: 0.7276\n",
      "Epoch 37/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4926 - acc: 0.6388 - val_loss: 1.0968 - val_acc: 0.7284\n",
      "Epoch 38/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4883 - acc: 0.6406 - val_loss: 1.0938 - val_acc: 0.7284\n",
      "Epoch 39/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4893 - acc: 0.6402 - val_loss: 1.0929 - val_acc: 0.7288\n",
      "Epoch 40/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4845 - acc: 0.6410 - val_loss: 1.0903 - val_acc: 0.7292\n",
      "Epoch 41/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4833 - acc: 0.6412 - val_loss: 1.0884 - val_acc: 0.7299\n",
      "Epoch 42/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4805 - acc: 0.6420 - val_loss: 1.0887 - val_acc: 0.7298\n",
      "Epoch 43/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4778 - acc: 0.6425 - val_loss: 1.0879 - val_acc: 0.7301\n",
      "Epoch 44/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4766 - acc: 0.6431 - val_loss: 1.0866 - val_acc: 0.7303\n",
      "Epoch 45/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4781 - acc: 0.6423 - val_loss: 1.0848 - val_acc: 0.7306\n",
      "Epoch 46/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4777 - acc: 0.6432 - val_loss: 1.0839 - val_acc: 0.7311\n",
      "Epoch 47/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4742 - acc: 0.6436 - val_loss: 1.0837 - val_acc: 0.7308\n",
      "Epoch 48/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4701 - acc: 0.6450 - val_loss: 1.0854 - val_acc: 0.7305\n",
      "Epoch 49/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4725 - acc: 0.6440 - val_loss: 1.0804 - val_acc: 0.7312\n",
      "Epoch 50/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4697 - acc: 0.6452 - val_loss: 1.0809 - val_acc: 0.7313\n",
      "Epoch 51/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4674 - acc: 0.6457 - val_loss: 1.0792 - val_acc: 0.7317\n",
      "Epoch 52/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4680 - acc: 0.6455 - val_loss: 1.0783 - val_acc: 0.7322\n",
      "Epoch 53/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4645 - acc: 0.6466 - val_loss: 1.0784 - val_acc: 0.7320\n",
      "Epoch 54/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4637 - acc: 0.6461 - val_loss: 1.0770 - val_acc: 0.7320\n",
      "Epoch 55/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4629 - acc: 0.6464 - val_loss: 1.0763 - val_acc: 0.7327\n",
      "Epoch 56/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4620 - acc: 0.6469 - val_loss: 1.0752 - val_acc: 0.7323\n",
      "Epoch 57/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4624 - acc: 0.6462 - val_loss: 1.0764 - val_acc: 0.7323\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4600 - acc: 0.6468 - val_loss: 1.0738 - val_acc: 0.7329\n",
      "Epoch 59/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4584 - acc: 0.6475 - val_loss: 1.0741 - val_acc: 0.7332\n",
      "Epoch 60/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4576 - acc: 0.6485 - val_loss: 1.0731 - val_acc: 0.7332\n",
      "Epoch 61/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4574 - acc: 0.6478 - val_loss: 1.0717 - val_acc: 0.7332\n",
      "Epoch 62/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4541 - acc: 0.6492 - val_loss: 1.0721 - val_acc: 0.7330\n",
      "Epoch 63/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4526 - acc: 0.6487 - val_loss: 1.0718 - val_acc: 0.7336\n",
      "Epoch 64/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4519 - acc: 0.6486 - val_loss: 1.0699 - val_acc: 0.7338\n",
      "Epoch 65/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4503 - acc: 0.6489 - val_loss: 1.0698 - val_acc: 0.7339\n",
      "Epoch 66/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4498 - acc: 0.6492 - val_loss: 1.0701 - val_acc: 0.7341\n",
      "Epoch 67/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4499 - acc: 0.6494 - val_loss: 1.0698 - val_acc: 0.7340\n",
      "Epoch 68/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4476 - acc: 0.6497 - val_loss: 1.0678 - val_acc: 0.7340\n",
      "Epoch 69/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4480 - acc: 0.6499 - val_loss: 1.0694 - val_acc: 0.7339\n",
      "Epoch 70/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4469 - acc: 0.6501 - val_loss: 1.0668 - val_acc: 0.7343\n",
      "Epoch 71/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4473 - acc: 0.6502 - val_loss: 1.0664 - val_acc: 0.7346\n",
      "Epoch 72/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4453 - acc: 0.6511 - val_loss: 1.0674 - val_acc: 0.7342\n",
      "Epoch 73/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4460 - acc: 0.6513 - val_loss: 1.0653 - val_acc: 0.7350\n",
      "Epoch 74/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4456 - acc: 0.6504 - val_loss: 1.0655 - val_acc: 0.7351\n",
      "Epoch 75/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4431 - acc: 0.6511 - val_loss: 1.0652 - val_acc: 0.7353\n",
      "Epoch 76/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4439 - acc: 0.6510 - val_loss: 1.0656 - val_acc: 0.7345\n",
      "Epoch 77/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4394 - acc: 0.6518 - val_loss: 1.0639 - val_acc: 0.7352\n",
      "Epoch 78/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4406 - acc: 0.6519 - val_loss: 1.0635 - val_acc: 0.7354\n",
      "Epoch 79/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4383 - acc: 0.6525 - val_loss: 1.0635 - val_acc: 0.7353\n",
      "Epoch 80/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4404 - acc: 0.6519 - val_loss: 1.0630 - val_acc: 0.7354\n",
      "Epoch 81/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4387 - acc: 0.6518 - val_loss: 1.0632 - val_acc: 0.7357\n",
      "Epoch 82/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4393 - acc: 0.6518 - val_loss: 1.0622 - val_acc: 0.7356\n",
      "Epoch 83/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4373 - acc: 0.6531 - val_loss: 1.0611 - val_acc: 0.7358\n",
      "Epoch 84/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4361 - acc: 0.6523 - val_loss: 1.0612 - val_acc: 0.7361\n",
      "Epoch 85/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4382 - acc: 0.6517 - val_loss: 1.0608 - val_acc: 0.7355\n",
      "Epoch 86/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4358 - acc: 0.6528 - val_loss: 1.0609 - val_acc: 0.7359\n",
      "Epoch 87/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4364 - acc: 0.6526 - val_loss: 1.0603 - val_acc: 0.7360\n",
      "Epoch 88/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4369 - acc: 0.6523 - val_loss: 1.0604 - val_acc: 0.7359\n",
      "Epoch 89/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4346 - acc: 0.6533 - val_loss: 1.0585 - val_acc: 0.7363\n",
      "Epoch 90/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4321 - acc: 0.6534 - val_loss: 1.0591 - val_acc: 0.7362\n",
      "Epoch 91/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4332 - acc: 0.6528 - val_loss: 1.0583 - val_acc: 0.7361\n",
      "Epoch 92/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4340 - acc: 0.6530 - val_loss: 1.0590 - val_acc: 0.7365loss: 1.4361  - ETA: 2s - loss: 1.4337 -\n",
      "Epoch 93/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4336 - acc: 0.6534 - val_loss: 1.0581 - val_acc: 0.7367\n",
      "Epoch 94/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4308 - acc: 0.6542 - val_loss: 1.0578 - val_acc: 0.7364\n",
      "Epoch 95/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4284 - acc: 0.6544 - val_loss: 1.0571 - val_acc: 0.7366\n",
      "Epoch 96/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4295 - acc: 0.6541 - val_loss: 1.0569 - val_acc: 0.7364\n",
      "Epoch 97/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4286 - acc: 0.6544 - val_loss: 1.0583 - val_acc: 0.7366\n",
      "Epoch 98/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4284 - acc: 0.6550 - val_loss: 1.0568 - val_acc: 0.7365\n",
      "Epoch 99/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4297 - acc: 0.6544 - val_loss: 1.0564 - val_acc: 0.7368\n",
      "Epoch 100/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4289 - acc: 0.6549 - val_loss: 1.0562 - val_acc: 0.7369\n",
      "Epoch 101/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4285 - acc: 0.6546 - val_loss: 1.0557 - val_acc: 0.7370\n",
      "Epoch 102/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4276 - acc: 0.6545 - val_loss: 1.0555 - val_acc: 0.7373\n",
      "Epoch 103/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4269 - acc: 0.6556 - val_loss: 1.0551 - val_acc: 0.7374\n",
      "Epoch 104/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4266 - acc: 0.6547 - val_loss: 1.0546 - val_acc: 0.7372\n",
      "Epoch 105/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4271 - acc: 0.6553 - val_loss: 1.0539 - val_acc: 0.7371\n",
      "Epoch 106/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4251 - acc: 0.6554 - val_loss: 1.0536 - val_acc: 0.7373\n",
      "Epoch 107/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4240 - acc: 0.6558 - val_loss: 1.0533 - val_acc: 0.7376\n",
      "Epoch 108/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4233 - acc: 0.6556 - val_loss: 1.0537 - val_acc: 0.7375\n",
      "Epoch 109/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4230 - acc: 0.6559 - val_loss: 1.0536 - val_acc: 0.7375\n",
      "Epoch 110/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4234 - acc: 0.6556 - val_loss: 1.0521 - val_acc: 0.7377\n",
      "Epoch 111/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4230 - acc: 0.6557 - val_loss: 1.0528 - val_acc: 0.7376\n",
      "Epoch 112/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4221 - acc: 0.6560 - val_loss: 1.0525 - val_acc: 0.7380\n",
      "Epoch 113/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4213 - acc: 0.6561 - val_loss: 1.0520 - val_acc: 0.7377\n",
      "Epoch 114/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4204 - acc: 0.6559 - val_loss: 1.0513 - val_acc: 0.7380\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4206 - acc: 0.6566 - val_loss: 1.0517 - val_acc: 0.7377\n",
      "Epoch 116/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4223 - acc: 0.6558 - val_loss: 1.0511 - val_acc: 0.7380\n",
      "Epoch 117/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4195 - acc: 0.6569 - val_loss: 1.0510 - val_acc: 0.7381\n",
      "Epoch 118/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4213 - acc: 0.6558 - val_loss: 1.0510 - val_acc: 0.7381\n",
      "Epoch 119/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4191 - acc: 0.6562 - val_loss: 1.0506 - val_acc: 0.7380\n",
      "Epoch 120/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4213 - acc: 0.6560 - val_loss: 1.0507 - val_acc: 0.7377\n",
      "Epoch 121/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4199 - acc: 0.6560 - val_loss: 1.0499 - val_acc: 0.7382\n",
      "Epoch 122/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4185 - acc: 0.6565 - val_loss: 1.0514 - val_acc: 0.7378\n",
      "Epoch 123/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4180 - acc: 0.6573 - val_loss: 1.0503 - val_acc: 0.7381\n",
      "Epoch 124/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4167 - acc: 0.6569 - val_loss: 1.0495 - val_acc: 0.7381\n",
      "Epoch 125/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4168 - acc: 0.6571 - val_loss: 1.0491 - val_acc: 0.7383\n",
      "Epoch 126/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4170 - acc: 0.6570 - val_loss: 1.0488 - val_acc: 0.7385\n",
      "Epoch 127/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4171 - acc: 0.6580 - val_loss: 1.0490 - val_acc: 0.7385\n",
      "Epoch 128/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4138 - acc: 0.6582 - val_loss: 1.0483 - val_acc: 0.7387\n",
      "Epoch 129/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4152 - acc: 0.6574 - val_loss: 1.0489 - val_acc: 0.7384\n",
      "Epoch 130/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4159 - acc: 0.6571 - val_loss: 1.0479 - val_acc: 0.7386\n",
      "Epoch 131/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4140 - acc: 0.6580 - val_loss: 1.0483 - val_acc: 0.7388\n",
      "Epoch 132/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4151 - acc: 0.6582 - val_loss: 1.0478 - val_acc: 0.7387\n",
      "Epoch 133/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4130 - acc: 0.6583 - val_loss: 1.0478 - val_acc: 0.7387\n",
      "Epoch 134/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4140 - acc: 0.6583 - val_loss: 1.0468 - val_acc: 0.7390\n",
      "Epoch 135/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4148 - acc: 0.6581 - val_loss: 1.0467 - val_acc: 0.7390\n",
      "Epoch 136/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4126 - acc: 0.6585 - val_loss: 1.0465 - val_acc: 0.7389\n",
      "Epoch 137/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4131 - acc: 0.6590 - val_loss: 1.0465 - val_acc: 0.7392\n",
      "Epoch 138/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4104 - acc: 0.6588 - val_loss: 1.0464 - val_acc: 0.7390\n",
      "Epoch 139/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4107 - acc: 0.6586 - val_loss: 1.0464 - val_acc: 0.7392\n",
      "Epoch 140/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4097 - acc: 0.6592 - val_loss: 1.0463 - val_acc: 0.7393\n",
      "Epoch 141/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4117 - acc: 0.6586 - val_loss: 1.0463 - val_acc: 0.7390\n",
      "Epoch 142/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4087 - acc: 0.6588 - val_loss: 1.0453 - val_acc: 0.7392\n",
      "Epoch 143/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4100 - acc: 0.6585 - val_loss: 1.0455 - val_acc: 0.7391\n",
      "Epoch 144/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4096 - acc: 0.6597 - val_loss: 1.0448 - val_acc: 0.7393\n",
      "Epoch 145/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4097 - acc: 0.6586 - val_loss: 1.0455 - val_acc: 0.7393\n",
      "Epoch 146/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4078 - acc: 0.6597 - val_loss: 1.0464 - val_acc: 0.7389\n",
      "Epoch 147/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4088 - acc: 0.6590 - val_loss: 1.0446 - val_acc: 0.7392\n",
      "Epoch 148/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4094 - acc: 0.6589 - val_loss: 1.0445 - val_acc: 0.7393\n",
      "Epoch 149/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4073 - acc: 0.6591 - val_loss: 1.0442 - val_acc: 0.7394\n",
      "Epoch 150/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4072 - acc: 0.6598 - val_loss: 1.0446 - val_acc: 0.7394\n",
      "Epoch 151/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4066 - acc: 0.6599 - val_loss: 1.0437 - val_acc: 0.7392\n",
      "Epoch 152/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4066 - acc: 0.6605 - val_loss: 1.0445 - val_acc: 0.7396\n",
      "Epoch 153/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4091 - acc: 0.6593 - val_loss: 1.0440 - val_acc: 0.7397\n",
      "Epoch 154/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4069 - acc: 0.6599 - val_loss: 1.0436 - val_acc: 0.7394\n",
      "Epoch 155/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4056 - acc: 0.6603 - val_loss: 1.0436 - val_acc: 0.7395\n",
      "Epoch 156/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4045 - acc: 0.6608 - val_loss: 1.0428 - val_acc: 0.7396\n",
      "Epoch 157/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4064 - acc: 0.6596 - val_loss: 1.0428 - val_acc: 0.7399\n",
      "Epoch 158/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4046 - acc: 0.6601 - val_loss: 1.0432 - val_acc: 0.7398\n",
      "Epoch 159/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4055 - acc: 0.6607 - val_loss: 1.0426 - val_acc: 0.7397\n",
      "Epoch 160/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4083 - acc: 0.6596 - val_loss: 1.0428 - val_acc: 0.7399\n",
      "Epoch 161/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4051 - acc: 0.6599 - val_loss: 1.0423 - val_acc: 0.7398\n",
      "Epoch 162/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4038 - acc: 0.6603 - val_loss: 1.0432 - val_acc: 0.7397\n",
      "Epoch 163/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4024 - acc: 0.6605 - val_loss: 1.0418 - val_acc: 0.7401\n",
      "Epoch 164/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4039 - acc: 0.6601 - val_loss: 1.0418 - val_acc: 0.7400\n",
      "Epoch 165/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4022 - acc: 0.6605 - val_loss: 1.0421 - val_acc: 0.7401\n",
      "Epoch 166/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4027 - acc: 0.6606 - val_loss: 1.0423 - val_acc: 0.7402\n",
      "Epoch 167/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4034 - acc: 0.6606 - val_loss: 1.0410 - val_acc: 0.7403\n",
      "Epoch 168/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4026 - acc: 0.6610 - val_loss: 1.0410 - val_acc: 0.7403\n",
      "Epoch 169/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4021 - acc: 0.6610 - val_loss: 1.0414 - val_acc: 0.7401\n",
      "Epoch 170/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4016 - acc: 0.6612 - val_loss: 1.0412 - val_acc: 0.7404\n",
      "Epoch 171/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4035 - acc: 0.6607 - val_loss: 1.0409 - val_acc: 0.7402\n",
      "Epoch 172/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4032 - acc: 0.6603 - val_loss: 1.0405 - val_acc: 0.7403\n",
      "Epoch 173/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4023 - acc: 0.6602 - val_loss: 1.0404 - val_acc: 0.7405\n",
      "Epoch 174/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4029 - acc: 0.6612 - val_loss: 1.0406 - val_acc: 0.7404\n",
      "Epoch 175/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.3993 - acc: 0.6614 - val_loss: 1.0405 - val_acc: 0.7406\n",
      "Epoch 176/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4010 - acc: 0.6606 - val_loss: 1.0397 - val_acc: 0.7405\n",
      "Epoch 177/200\n",
      "600000/600000 [==============================] - 14s 24us/step - loss: 1.4001 - acc: 0.6618 - val_loss: 1.0401 - val_acc: 0.7406\n",
      "Epoch 178/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4022 - acc: 0.6618 - val_loss: 1.0400 - val_acc: 0.7404\n",
      "Epoch 179/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.3995 - acc: 0.6614 - val_loss: 1.0401 - val_acc: 0.7405\n",
      "Epoch 180/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4014 - acc: 0.6612 - val_loss: 1.0396 - val_acc: 0.7405\n",
      "Epoch 181/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.3994 - acc: 0.6608 - val_loss: 1.0396 - val_acc: 0.7407\n",
      "Epoch 182/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.3998 - acc: 0.6616 - val_loss: 1.0396 - val_acc: 0.7407\n",
      "Epoch 183/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.3994 - acc: 0.6614 - val_loss: 1.0394 - val_acc: 0.7405\n",
      "Epoch 184/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.4009 - acc: 0.6608 - val_loss: 1.0394 - val_acc: 0.7405\n",
      "Epoch 185/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.3976 - acc: 0.6614 - val_loss: 1.0391 - val_acc: 0.7406\n",
      "Epoch 186/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.3968 - acc: 0.6622 - val_loss: 1.0387 - val_acc: 0.7406\n",
      "Epoch 187/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.3998 - acc: 0.6612 - val_loss: 1.0390 - val_acc: 0.7408\n",
      "Epoch 188/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.3987 - acc: 0.6619 - val_loss: 1.0387 - val_acc: 0.7406\n",
      "Epoch 189/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.3962 - acc: 0.6619 - val_loss: 1.0381 - val_acc: 0.7407\n",
      "Epoch 190/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.3973 - acc: 0.6628 - val_loss: 1.0381 - val_acc: 0.7407\n",
      "Epoch 191/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.3968 - acc: 0.6628 - val_loss: 1.0379 - val_acc: 0.7409\n",
      "Epoch 192/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.3966 - acc: 0.6617 - val_loss: 1.0379 - val_acc: 0.7406\n",
      "Epoch 193/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.3984 - acc: 0.6621 - val_loss: 1.0375 - val_acc: 0.7408\n",
      "Epoch 194/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.3954 - acc: 0.6624 - val_loss: 1.0378 - val_acc: 0.7410\n",
      "Epoch 195/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.3963 - acc: 0.6620 - val_loss: 1.0376 - val_acc: 0.7410\n",
      "Epoch 196/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.3972 - acc: 0.6626 - val_loss: 1.0373 - val_acc: 0.7408\n",
      "Epoch 197/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.3951 - acc: 0.6624 - val_loss: 1.0381 - val_acc: 0.7411\n",
      "Epoch 198/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.3947 - acc: 0.6630 - val_loss: 1.0378 - val_acc: 0.7410\n",
      "Epoch 199/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.3951 - acc: 0.6625 - val_loss: 1.0377 - val_acc: 0.7411\n",
      "Epoch 200/200\n",
      "600000/600000 [==============================] - 14s 23us/step - loss: 1.3950 - acc: 0.6621 - val_loss: 1.0370 - val_acc: 0.7412\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = 10000\n",
    "epochs = 200\n",
    "\n",
    "history = model.fit(x_train,y_train,batch_size=batch_sizes,epochs=epochs,verbose=1,validation_data=(x_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Visualize train process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_train(hist):\n",
    "    h = hist.history\n",
    "    if 'acc' in h:\n",
    "        meas='acc'\n",
    "        loc='lower right'\n",
    "    else:\n",
    "        meas='loss'\n",
    "        loc='upper right'\n",
    "    plt.plot(hist.history[meas])\n",
    "    plt.plot(hist.history['val_'+meas])\n",
    "    plt.title('model '+meas)\n",
    "    plt.ylabel(meas)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc=loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x290c28e2710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Evaluate & save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000/300000 [==============================] - 19s 62us/step\n",
      "Validation Accuracy =  0.741186666667\n",
      "Validation Loss =  1.03703028741\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_validation,y_validation,verbose=1)\n",
    "\n",
    "print(\"Validation Accuracy = \", score[1])\n",
    "print(\"Validation Loss = \", score[0])\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 8: Let's make some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 74.128 %\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_test)\n",
    "count = 0\n",
    "correct = 0\n",
    "\n",
    "for r in result:\n",
    "    idx = np.argmax(r)\n",
    "    gt = np.argmax(y_test[count])\n",
    "    if idx == gt:\n",
    "        correct = correct + 1\n",
    "    count = count + 1\n",
    "\n",
    "print('Test Accuracy:', correct/count*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x290c2bc6550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label index of this data is: 83 -- face\n"
     ]
    }
   ],
   "source": [
    "show_object(x_test[666])\n",
    "print('The label index of this data is: %d' % np.argmax(y_test[666]),'--',classes[np.argmax(y_test[666])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
