{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 3: RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Length: 1115394\n"
     ]
    }
   ],
   "source": [
    "text = open('input.txt',encoding='utf8').read().lower()\n",
    "print('Text Length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chars:  39\n",
      "Total Sentences:  111530\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# Cut the text into small sentences with fixed length\n",
    "txtlen = 100\n",
    "step = 10\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - txtlen, step):\n",
    "    sentences.append(text[i: i + txtlen])\n",
    "    next_chars.append(text[i + txtlen])\n",
    "\n",
    "print('Total Chars: ', len(chars))\n",
    "print('Total Sentences: ', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.zeros((len(sentences), txtlen, len(chars)), dtype=np.bool)\n",
    "y_train = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_train[i, t, char_indices[char]] = 1\n",
    "    y_train[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               86016     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 39)                5031      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 39)                0         \n",
      "=================================================================\n",
      "Total params: 91,047\n",
      "Trainable params: 91,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# LSTM\n",
    "model.add(LSTM(128, input_shape=(txtlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "rms = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rms)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Let's make some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, diversity=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    log_preds = np.log(preds) / diversity\n",
    "    exp_preds = np.exp(log_preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 15s 139us/step - loss: 2.5997\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 2.0306\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.8343\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.7170\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.6353\n",
      "\n",
      "---------- Generating with: ----------\n",
      ":\n",
      "a match!\n",
      "\n",
      "adrian:\n",
      "though this island seem to be desert,--\n",
      "\n",
      "sebastian:\n",
      "ha, ha, ha! so, you're paid.\n",
      "\n",
      "---------- Prediction: ----------\n",
      "\n",
      "\n",
      "nirsto:\n",
      "gat i sadeby for in that laicls rowns;\n",
      "all my donemas; and i bestechisk.\n",
      "and was bring of mistive hist mus it forle\n",
      "thes all gavely toy, say here the trupins'\n",
      "tage mest cbosing, that,\n",
      "as ho their king, now wnom\n",
      "of cloop scorned band brood the catible.\n",
      "\n",
      "bostonga:\n",
      "doth apor lidy light; on th\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 120us/step - loss: 1.5718\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 120us/step - loss: 1.5224\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.4792\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.4401\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.4068\n",
      "\n",
      "---------- Generating with: ----------\n",
      "ave this crown of mine cut from my shoulders\n",
      "ere i will see the crown so foul misplaced.\n",
      "but canst t\n",
      "\n",
      "---------- Prediction: ----------\n",
      "he forsh my plowits iffers.\n",
      "\n",
      "duke of york:\n",
      "thou, stedines 'tis fauks, sheded him hornos?\n",
      "\n",
      "aniostingblused:\n",
      "must most knoble at all theus loved.\n",
      "\n",
      "gloucester:\n",
      "we have band 'mall marce, dram loke? the deate, good good\n",
      "for thou sheli, kind compance from helly,\n",
      "how cound gloucestans, look, in kindance.\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 118us/step - loss: 1.3763\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.3518\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.3283\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.3061\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.2866\n",
      "\n",
      "---------- Generating with: ----------\n",
      "r again\n",
      "is my kinsman, whom the king hath wrong'd,\n",
      "whom conscience and my kindred bids to right.\n",
      "wel\n",
      "\n",
      "---------- Prediction: ----------\n",
      "l kenger's it unis i pain would is be reade, munjesh.\n",
      "\n",
      "slovd:\n",
      "now, which came for it,\n",
      "pobles, is all shide would voite. he istitaf thee wasged\n",
      "what them our peting,\n",
      "boand up awind and batt,\n",
      "to husbarm them. the valeater, as thironclased,\n",
      "which eyess our in to than prowny: fighty wich richarl'd engle\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 118us/step - loss: 1.2703\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.2565\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 118us/step - loss: 1.2447\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.2294\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.2206\n",
      "\n",
      "---------- Generating with: ----------\n",
      "\n",
      "when my poor heart no measure keeps in grief:\n",
      "therefore, no dancing, girl; some other sport.\n",
      "\n",
      "lady:\n",
      "\n",
      "---------- Prediction: ----------\n",
      "\n",
      "wheresward she well wittiel.\n",
      "\n",
      "verid:\n",
      "all your papter corrain. i speak from himshighinds,\n",
      "whint stenlo was princely all choporion.\n",
      "\n",
      "colionous:\n",
      "and those his croth.\n",
      "\n",
      "xicterio:\n",
      "the comfort.\n",
      "\n",
      "duke of gloubestio:\n",
      "say a haply ones so in oath our\n",
      "ateal-bawing of us thou art,\n",
      "to the findrer say: iqure he s\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.2134\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 118us/step - loss: 1.2004\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 121us/step - loss: 1.1926\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 120us/step - loss: 1.1844\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 118us/step - loss: 1.1802\n",
      "\n",
      "---------- Generating with: ----------\n",
      "irer than my love! the all-seeing sun\n",
      "ne'er saw her match since first the world begun.\n",
      "\n",
      "benvolio:\n",
      "tu\n",
      "\n",
      "---------- Prediction: ----------\n",
      "r we have alvess dischy coir; behome of that misleath.\n",
      "\n",
      "nubse:\n",
      "marry so be in forfe!\n",
      "\n",
      "king edward iv:\n",
      "ye will! what some not it abit him,\n",
      "and are the slook the chablires, why angee and as our neblry ho.\n",
      "\n",
      "sicinius:\n",
      "if thou to a thou desceed us when,\n",
      "and the ence intomisis, that i sor,\n",
      "what thou wert \n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.1736\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.1646\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 118us/step - loss: 1.1604\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.1549\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.1530\n",
      "\n",
      "---------- Generating with: ----------\n",
      "ore her blessing. lady,\n",
      "dear queen, that ended when i but began,\n",
      "give me that hand of yours to kiss.\n",
      "\n",
      "---------- Prediction: ----------\n",
      "\n",
      "\n",
      "cifionus:\n",
      "marcanush, i set on him:\n",
      "but for's put by the pursuch prould instled\n",
      "of hard sigh us confessee, but send but opliment a sun\n",
      "le murting and just and hatted,\n",
      "read give i am selven so!\n",
      "\n",
      "books:\n",
      "most twince his break pressele, faluub'd matte.\n",
      "\n",
      "bombryeace:\n",
      "romeo! such asherp 's missteng untich\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.1481\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.1422\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.1400\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 120us/step - loss: 1.1345\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.1315\n",
      "\n",
      "---------- Generating with: ----------\n",
      "h,\n",
      "call home thy ancient thoughts from banishment\n",
      "and banish hence these abject lowly dreams.\n",
      "look h\n",
      "\n",
      "---------- Prediction: ----------\n",
      "ast not would be wanks, when me.\n",
      "\n",
      "escalus:\n",
      "morney is the brother stray;\n",
      "i had a care will in the ochiencely,\n",
      "\n",
      "asgee:\n",
      "well, ca"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rk! what the disgived so look of changed\n",
      "of soin be instory pards breaken and tymel.\n",
      "when icabe! well-twex your honour venge; steen concerves\n",
      "than my good titr toolly an lew a\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.1277\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.1233\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 118us/step - loss: 1.1223\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.1168\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.1138\n",
      "\n",
      "---------- Generating with: ----------\n",
      "ding to your love,\n",
      "and little look'd for at your helping hands.\n",
      "\n",
      "king richard ii:\n",
      "alack, why am i se\n",
      "\n",
      "---------- Prediction: ----------\n",
      "n, breck acquuesion abolest\n",
      "stayely had an'er, not in this death.\n",
      "\n",
      "are togome:\n",
      "me to agaves but unto thines. your dead.\n",
      "\n",
      "blurnes:\n",
      "then his! live must shoind richard.\n",
      "\n",
      "second citize:\n",
      "ah, looks! where's dine, i hear boats of unquast be,\n",
      "i wentersual sleaks; as look'd to their soul.\n",
      "\n",
      "queen elizabeth:\n",
      "t\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.1111\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.1090\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 118us/step - loss: 1.1064\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.1042\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 120us/step - loss: 1.1031\n",
      "\n",
      "---------- Generating with: ----------\n",
      "o no, my reasons are too deep and dead;\n",
      "too deep and dead, poor infants, in their grave.\n",
      "\n",
      "king richa\n",
      "\n",
      "---------- Prediction: ----------\n",
      "rdsii:\n",
      "i fish our kind\n",
      "what loves!\n",
      "\n",
      "morted be made--\n",
      "dushas pray your breats of his may?\n",
      "and what thou doth in the prey upon his defore;\n",
      "thy death, runt love? peaces all me till here and lancaster,\n",
      "to promised fallis, a trittely arm,\n",
      "that in chases, if thou stay's this\n",
      "rest in his poor holior with m\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.1000\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 118us/step - loss: 1.0985\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 118us/step - loss: 1.0926\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.0921\n",
      "Epoch 1/1\n",
      "111530/111530 [==============================] - 13s 119us/step - loss: 1.0925\n",
      "\n",
      "---------- Generating with: ----------\n",
      "thee,\n",
      "but thou slew'st tybalt; there are thou happy too:\n",
      "the law that threaten'd death becomes thy f\n",
      "\n",
      "---------- Prediction: ----------\n",
      "ree\n",
      "the blouds. what cantenstirie faps, marry, upon mister,\n",
      "nor on these gentleman: flat your father!\n",
      "i hap the liefer ty analuse.\n",
      "meng enismantio, he ence these or?\n",
      "such to done. where youngless hath nother hath a strung.\n",
      "\n",
      "duke vincentio:\n",
      "this excle and to be being a man:\n",
      "up appool grave mine is fo\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "epochs = 1\n",
    "\n",
    "diversity = 1.0\n",
    "\n",
    "for i in range(1,51):\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n",
    "    start_point = random.randint(0, len(text) - txtlen - 1)\n",
    "    \n",
    "    if i%5 == 0:\n",
    "        \n",
    "        generated = ''\n",
    "        sentence = text[start_point : start_point + txtlen]\n",
    "        generated += sentence\n",
    "        print('\\n---------- Generating with: ----------')\n",
    "        print(generated)\n",
    "        print('\\n---------- Prediction: ----------')\n",
    "        \n",
    "        for i in range(300):\n",
    "            x_pred = np.zeros((1, txtlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        print()\n",
    "        \n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
