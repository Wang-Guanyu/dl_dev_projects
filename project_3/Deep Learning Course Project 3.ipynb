{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 3: RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Length: 4224142\n"
     ]
    }
   ],
   "source": [
    "text = open('obama.txt',encoding='utf8').read().lower()\n",
    "print('Text Length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chars:  94\n",
      "Total Sentences:  422405\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# Cut the text into small sentences with fixed length\n",
    "txtlen = 100\n",
    "step = 10\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - txtlen, step):\n",
    "    sentences.append(text[i: i + txtlen])\n",
    "    next_chars.append(text[i + txtlen])\n",
    "\n",
    "print('Total Chars: ', len(chars))\n",
    "print('Total Sentences: ', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.zeros((len(sentences), txtlen, len(chars)), dtype=np.bool)\n",
    "y_train = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_train[i, t, char_indices[char]] = 1\n",
    "    y_train[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 128)               114176    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 94)                12126     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 94)                0         \n",
      "=================================================================\n",
      "Total params: 126,302\n",
      "Trainable params: 126,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# LSTM\n",
    "model.add(LSTM(128, input_shape=(txtlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "rms = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rms)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Let's make some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, diversity=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    log_preds = np.log(preds) / diversity\n",
    "    exp_preds = np.exp(log_preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 141us/step - loss: 2.0924\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.5848\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 137us/step - loss: 1.4511\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.3875\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.3457\n",
      "\n",
      "---------- Generating with: ----------\n",
      "nation builders.”  here in america, it’s time we treated the people who educate our children with th\n",
      "\n",
      "---------- Prediction: ----------\n",
      "em.  effiding.  it’s membe ar"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "romation for the insolace. it’s upination. on that crimom life-experts with ourselves we la-ter from vire  and 19vid.  i alliarceess the flewil somemonaly, “understand unlome, tom obli\"d. states and chasies, and$ even the nopong uses. no  alinables, pulled voice.\n",
      "\n",
      "but th\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.3203\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.2992\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.2814\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 139us/step - loss: 1.2661\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.2546\n",
      "\n",
      "---------- Generating with: ----------\n",
      "economy. and that’s why i’ve directed the federal government to hire more veterans, including more t\n",
      "\n",
      "---------- Prediction: ----------\n",
      "wosely and  because his clange safey than from the moment, one of harm toot anveruning wheppen or so importantly cormbut.\n",
      "\n",
      "you could go the global ways that is this nation of every disponey, without isn’t an and gobby for a famility. \n",
      "\n",
      "now, own and youbs that day a cuba is you.  kinghered foding vic\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.2444\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.2363\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.2302\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.2232\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.2161\n",
      "\n",
      "---------- Generating with: ----------\n",
      "ched america's improbable experiment in democracy. farmers and scholars, statesmen and patriots who \n",
      "\n",
      "---------- Prediction: ----------\n",
      "asked to leak treak dependence on toray and they don’t also help.\n",
      "\n",
      "and it is ally. but we cake our memories.  we’ve got to avoid the fact and our under it just this times to make in the people has must ba some paid briets nation one enterpout that you heavo home that we've done the very later it sai\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.2156\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.2100\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 137us/step - loss: 1.2051\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.2033\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1998\n",
      "\n",
      "---------- Generating with: ----------\n",
      "e ideas.\n",
      "\n",
      "the greatest untapped resource in the middle east and north africa is the talent of its pe\n",
      "\n",
      "---------- Prediction: ----------\n",
      "ople like already authority is would four house that’s while or american life does with the comministig for the killing commissions are loor-was four or enjoy. we have word in the peaces sayizan cut through time -- that didn’t get what i thank you.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "now hard has even in essentability, innocent \n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1961\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1930\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1901\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 139us/step - loss: 1.1875\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 139us/step - loss: 1.1751\n",
      "\n",
      "---------- Generating with: ----------\n",
      "ssing any laws to be here tonight.  let’s give them a big round of applause.\n",
      "\n",
      "despite many obstacles\n",
      "\n",
      "---------- Prediction: ----------\n",
      "., live that speech as on thousands of jobs, that stand by before we gave earnen manityring hither will actually come to the american short on use.\n",
      "\n",
      "who expect of the same to victory to be.  a few omacation that plan that were counterportsoleffe.\n",
      "\n",
      "the boyoning just beaction, their being to make me p\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1819\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1866\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1824\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1791\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1768\n",
      "\n",
      "---------- Generating with: ----------\n",
      "rld war ii. he was a soldier in patton’s army; she was a worker on a bomber assembly line. and toget\n",
      "\n",
      "---------- Prediction: ----------\n",
      "her our missibs insident officers is in all of you that becauseshhret rette that.  you protuef teachers, and all obstand.\n",
      "\n",
      "it support the capacity on american teds, i’m creating a hand.  in the region haven to work another the immeress that the degnt of women get those who our own chanced enforce ec\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1752\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 137us/step - loss: 1.1731\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 137us/step - loss: 1.1719\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1613\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1686\n",
      "\n",
      "---------- Generating with: ----------\n",
      "e early '90s.\n",
      "\n",
      "our largest companies are suffering, as well. a big part of what led general motors a\n",
      "\n",
      "---------- Prediction: ----------\n",
      "nd political ofd, we need to experience more finally fordal and these a jurgeesting their intelligence across, will wokhe rame programs and coming; to child with their ereast with you.  nearly weeks to make sure that rall and we must lift we have been solmed that the brinks and form accusiver of thi\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 137us/step - loss: 1.1668\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1647\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1628\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1622\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1610\n",
      "\n",
      "---------- Generating with: ----------\n",
      " made up of tax cuts for families and small businesses.  and when you think back to the health care \n",
      "\n",
      "---------- Prediction: ----------\n",
      "financiak of the winned to out,oway and some of the flew center the week, like people armue, “we sit ?\n",
      " “ohesration it’s over that decade air shops of demandeds serve our veterans is remembers who won't facts us program that confurenn that a ground and these strong outsalies in our assers of standar\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 139us/step - loss: 1.1596\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 139us/step - loss: 1.1588\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1575\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1559\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1551\n",
      "\n",
      "---------- Generating with: ----------\n",
      "g to make spending cuts -- many of which we wouldn’t make if we weren’t facing such large budget def\n",
      "\n",
      "---------- Prediction: ----------\n",
      "icit:  what we appedmed the company, people beliaold.  america, partinations in parh around the holding in their opportunities state inspiriance believes it charge humer losting firs insecurity of an exincers we want, buttine making a own all our future -- who -- i’ll respond beyond, and that very i\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1536\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 139us/step - loss: 1.1523\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1518\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1505\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1506\n",
      "\n",
      "---------- Generating with: ----------\n",
      "m now, and say we took care of our business and we put an end to some of these games that maybe, i g\n",
      "\n",
      "---------- Prediction: ----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uide these fair.  they also healthy welce. provided.  but when i'm going to safety an europe can said, and singy iraq we engaging brairm us in the path, and i spend the sanced is to strengthen john is the needic.  and so that i was important to seek his iels of americans that can pake; gives.\n",
      "\n",
      "onlat\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1492\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1474\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1473\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 139us/step - loss: 1.1464\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 139us/step - loss: 1.1454\n",
      "\n",
      "---------- Generating with: ----------\n",
      "pass health care right now, a plan that guarantees insurance to every american who wants it and brin\n",
      "\n",
      "---------- Prediction: ----------\n",
      "ks to acknowled to businest a fact that our dream measure of as entire natrace:  i’m fimmonged alocumest time and is on declassions is a world-agen, and no faith new justice from the careet than we are all more forces to spend availos most, already, that new and so today for americans to raited abou\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1447\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 139us/step - loss: 1.1449\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 139us/step - loss: 1.1435\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 139us/step - loss: 1.1430\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 139us/step - loss: 1.1425\n",
      "\n",
      "---------- Generating with: ----------\n",
      "wages as the smart way to boost productivity and reduce turnover. we should too.  in the coming week\n",
      "\n",
      "---------- Prediction: ----------\n",
      "s is appleate from the grocing roads in lifetness and pocketls, better. understand.  now we will warkful detant you control -- that they and level for exton as strong situaid can different action at their place, we often like pounts, now we get there will makes one washed on the approaking up and un\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 139us/step - loss: 1.1412\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 139us/step - loss: 1.1406\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1406\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1392\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1380\n",
      "\n",
      "---------- Generating with: ----------\n",
      " forces to iraq or syria.  it is not the authorization of another ground war, like afghanistan or ir\n",
      "\n",
      "---------- Prediction: ----------\n",
      "refeems, and let us invesement, dictates chuldens that invisiple for antitivibles and parency insurance wite freedom. and againseds of put them. but accepta here in this department. the qualify.  grought all this advice in those meaus than a pull. \n",
      "\n",
      "now, everyach to ouidavile the values of plan.  an\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1379\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1371\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1364\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1373\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1370\n",
      "\n",
      "---------- Generating with: ----------\n",
      "s. that means resisting the walls of protectionism that stand in the way of growth. that means a cha\n",
      "\n",
      "---------- Prediction: ----------\n",
      "llenges that determined a fillem and wonnedy and i coming fundantic how president who profession that a bands, to remoste you, that israel has ends -- case behalf of it and far the hearts, in the land in vebaration can result of to virte of our government -- tomorror wroging sebiling than we're safe\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 139us/step - loss: 1.1362\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1350\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1355\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 139us/step - loss: 1.1341\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1327\n",
      "\n",
      "---------- Generating with: ----------\n",
      "nnounced today.  i will devote the resources to centralize and improve the process we use to handle \n",
      "\n",
      "---------- Prediction: ----------\n",
      "you that get of movement for pennye before to worth states and peace, and paying europe where we applen us to this sacrifice al qaeda to end morn after, but the people for convemed, story to 6 this races he announct attacked with his bill on the maintains don't must be toxing ground and by secretary\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 139us/step - loss: 1.1330\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1312\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1310\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 139us/step - loss: 1.1308\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1303\n",
      "\n",
      "---------- Generating with: ----------\n",
      " because we believe that upholding peace and security is the responsibility of every nation.  the da\n",
      "\n",
      "---------- Prediction: ----------\n",
      "y, nor why i know that this last threatons has any party. that’s our economy and on worked. i know the that crime about never wave.  and lead more have more bumbre. so the administrat memoring nor division warrioon so porentional churelishcoffi20 that i come an its bips. and at hard, endures to one \n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1305\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 139us/step - loss: 1.1292\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1278\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 139us/step - loss: 1.1278\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1276\n",
      "\n",
      "---------- Generating with: ----------\n",
      "from a distance, sometimes these commemorations seem inevitable, they seem easy.  all the pain and d\n",
      "\n",
      "---------- Prediction: ----------\n",
      "ecisions is world to pay our financial mandets of americans who tell that america perfect by pas sufficher agreements, and good force will bring john our every proposal can spoke it consumer from moreoversiming, for the generation against evaripty going to mread afrimary.  can elic down cealable to \n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1281\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 139us/step - loss: 1.1267\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1274\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1260\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1258\n",
      "\n",
      "---------- Generating with: ----------\n",
      ", and education of black and brown and white children will ultimately help all of america prosper.\n",
      "\n",
      "\n",
      "\n",
      "---------- Prediction: ----------\n",
      "why, this brates -- more dealing to meet carry that wasn of the greatest forces in the round to i said, they did not forled our transphose programs that have been in people who were means haidler nations and all who worker -– toget the morn aust us sigation and safe, we passed more and our executive\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1256\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 140us/step - loss: 1.1256\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 59s 139us/step - loss: 1.1247\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1240\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1233\n",
      "\n",
      "---------- Generating with: ----------\n",
      "we have no interest in occupying afghanistan. we have more than enough to do in rebuilding america. \n",
      "\n",
      "---------- Prediction: ----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " you can be taking this happens in the mallear of the jobs work.\n",
      "\n",
      "this's 't this country here, something come home to choice in iraq, in a globe to the economic phone systamiests interest fody. this ceilitor puth.\n",
      "\n",
      "if was long acsobs election that we know we know we phy rown by the world have been u\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1234\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1226\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 137us/step - loss: 1.1230\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1229\n",
      "Epoch 1/1\n",
      "422405/422405 [==============================] - 58s 138us/step - loss: 1.1226\n",
      "\n",
      "---------- Generating with: ----------\n",
      "sanctioned by law or by custom.  and before the civil rights movement, it most surely was.\n",
      "\n",
      "we do a \n",
      "\n",
      "---------- Prediction: ----------\n",
      "lot of energy isirment, and someone.  and if we found the 20throaders have, for if he government.  it is stort.  partnership most direricus -- they’re 500 peopled law renabording indeppite for our profit in brings to go to meet what has been our responsibilities. and i want it in this arms like impo\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "epochs = 1\n",
    "\n",
    "diversity = 1.0\n",
    "\n",
    "for i in range(1,101):\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n",
    "    start_point = random.randint(0, len(text) - txtlen - 1)\n",
    "    \n",
    "    if i%5 == 0:\n",
    "        \n",
    "        generated = ''\n",
    "        sentence = text[start_point : start_point + txtlen]\n",
    "        generated += sentence\n",
    "        print('\\n---------- Generating with: ----------')\n",
    "        print(generated)\n",
    "        print('\\n---------- Prediction: ----------')\n",
    "        \n",
    "        for i in range(300):\n",
    "            x_pred = np.zeros((1, txtlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        print()\n",
    "        \n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
